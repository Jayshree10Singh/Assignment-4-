{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4beb74ac",
   "metadata": {},
   "source": [
    "# Assignment-4 (Web Scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9cafb5",
   "metadata": {},
   "source": [
    "### Answer-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e027b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary\n",
    "\n",
    "import pandas as pd\n",
    "import selenium\n",
    "import time\n",
    "from bs4 import BeautifulSoup \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "import re\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa68a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# Getting the webpage of url \n",
    "\n",
    "url=('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c404a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list for storing data after scraping\n",
    "\n",
    "Rank = []\n",
    "Name = []\n",
    "Artist = []\n",
    "UploadDate = []\n",
    "Views = []\n",
    "\n",
    "\n",
    "# Scraping Rank of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "    \n",
    "#scrapping rank\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\"):\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append(\"_\")\n",
    "    \n",
    "    \n",
    "#scrapping Artist\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//*[@id=\"mw-content-text\"]/div[1]/table[2]/tbody/tr/td[3]'):\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append(\"_\")\n",
    "    \n",
    "    \n",
    "#Scrapping Date\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,' //table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]'):\n",
    "        UploadDate.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    UploadDate.append('-')\n",
    "# Scraping Views of videos\n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\"):\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append(\"_\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33f43497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame from scraped data\n",
    "wikipedia = pd.DataFrame({})\n",
    "wikipedia['Rank']=Rank\n",
    "wikipedia['Name']=Name\n",
    "wikipedia['Artist']=Artist\n",
    "wikipedia['Upload Date']=UploadDate\n",
    "wikipedia['Views']=Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fd0b1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[3]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>11.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[6]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[12]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[13]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[15]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Bath Song\"[20]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[21]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>4.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[22]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[23]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Gangnam Style\"[24]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[29]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Wheels on the Bus\"[30]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[31]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[32]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[33]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[34]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Sorry\"[35]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Axel F\"[36]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Thinking Out Loud\"[37]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[38]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Dark Horse\"[39]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Faded\"[40]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[41]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[42]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Bailando\"[43]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Lean On\"[44]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Perfect\"[45]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[46]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Shake It Off\"[47]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[3]   \n",
       "1    2.                                   \"Despacito\"[6]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[12]   \n",
       "3    4.                               \"Shape of You\"[13]   \n",
       "4    5.                              \"See You Again\"[15]   \n",
       "5    6.                                  \"Bath Song\"[20]   \n",
       "6    7.                \"Phonics Song with Two Words\"[21]   \n",
       "7    8.                                \"Uptown Funk\"[22]   \n",
       "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[23]   \n",
       "9   10.                              \"Gangnam Style\"[24]   \n",
       "10  11.   \"Masha and the Bear – Recipe for Disaster\"[29]   \n",
       "11  12.                          \"Wheels on the Bus\"[30]   \n",
       "12  13.                             \"Dame Tu Cosita\"[31]   \n",
       "13  14.                                      \"Sugar\"[32]   \n",
       "14  15.                                       \"Roar\"[33]   \n",
       "15  16.                             \"Counting Stars\"[34]   \n",
       "16  17.                                      \"Sorry\"[35]   \n",
       "17  18.                                     \"Axel F\"[36]   \n",
       "18  18.                          \"Thinking Out Loud\"[37]   \n",
       "19  20.                        \"Baa Baa Black Sheep\"[38]   \n",
       "20  21.                                 \"Dark Horse\"[39]   \n",
       "21  22.                                      \"Faded\"[40]   \n",
       "22  23.                             \"Girls Like You\"[41]   \n",
       "23  24.                                 \"Let Her Go\"[42]   \n",
       "24  25.                                   \"Bailando\"[43]   \n",
       "25  26.                                    \"Lean On\"[44]   \n",
       "26  27.                                    \"Perfect\"[45]   \n",
       "27  28.           \"Waka Waka (This Time for Africa)\"[46]   \n",
       "28  29.                               \"Shake It Off\"[47]   \n",
       "29  30.          \"Humpty the train on a fruits ride\"[48]   \n",
       "\n",
       "                                           Artist        Upload Date  Views  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  11.30  \n",
       "1                                      Luis Fonsi   January 12, 2017   7.97  \n",
       "2                                     LooLoo Kids    October 8, 2016   6.45  \n",
       "3                                      Ed Sheeran   January 30, 2017   5.80  \n",
       "4                                     Wiz Khalifa      April 6, 2015   5.63  \n",
       "5                      Cocomelon – Nursery Rhymes        May 2, 2018   5.60  \n",
       "6                                       ChuChu TV      March 6, 2014   4.87  \n",
       "7                                     Mark Ronson  November 19, 2014   4.68  \n",
       "8                                     Miroshka TV  February 27, 2018   4.61  \n",
       "9                                             Psy      July 15, 2012   4.54  \n",
       "10                                     Get Movies   January 31, 2012   4.51  \n",
       "11                     Cocomelon – Nursery Rhymes       May 24, 2018   4.34  \n",
       "12                                      El Chombo      April 5, 2018   4.06  \n",
       "13                                       Maroon 5   January 14, 2015   3.75  \n",
       "14                                     Katy Perry  September 5, 2013   3.65  \n",
       "15                                    OneRepublic       May 31, 2013   3.64  \n",
       "16                                  Justin Bieber   October 22, 2015   3.58  \n",
       "17                                     Crazy Frog      June 16, 2009   3.50  \n",
       "18                                     Ed Sheeran    October 7, 2014   3.49  \n",
       "19                     Cocomelon – Nursery Rhymes      June 25, 2018   3.36  \n",
       "20                                     Katy Perry  February 20, 2014   3.34  \n",
       "21                                    Alan Walker   December 3, 2015   3.34  \n",
       "22                                       Maroon 5       May 31, 2018   3.33  \n",
       "23                                      Passenger      July 25, 2012   3.29  \n",
       "24                               Enrique Iglesias     April 11, 2014   3.26  \n",
       "25                                    Major Lazer     March 22, 2015   3.26  \n",
       "26                                     Ed Sheeran   November 9, 2017   3.25  \n",
       "27                                        Shakira       June 4, 2010   3.24  \n",
       "28                                   Taylor Swift    August 18, 2014   3.20  \n",
       "29  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   3.15  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a76a5318",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9b7f2e",
   "metadata": {},
   "source": [
    "## Answer-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c4248ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# Getting the webpage of mentioned url \n",
    "url=('https://www.bcci.tv/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19a7ce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clickin on International tab\n",
    "International = driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a') # click button\n",
    "International.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff0ed072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Empty List\n",
    "Name=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "#Scrapping Name\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]'):\n",
    "        Name.append(i.text.replace('-',\"\"))\n",
    "except NoSuchElementException:\n",
    "    Name.append('-')\n",
    "\n",
    "#Scrapping Series\n",
    "try:\n",
    "    \n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]'):\n",
    "        Series.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Series.append('-')\n",
    "#scrapping Place\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]'):\n",
    "        Place.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Place.append('-')\n",
    "#Scrapping Date\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//h5[@class=\"ng-binding\"]'):\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append('-')\n",
    "#Scrapping Time\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]'):\n",
    "        Time.append(i.text.replace('IST',\"\"))\n",
    "except NoSuchElementException:\n",
    "    Time.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de9931b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframe\n",
    "\n",
    "Fixtures=pd.DataFrame({})\n",
    "Fixtures['Title']=Series\n",
    "Fixtures['Name']=Name\n",
    "Fixtures['Place']=Place\n",
    "Fixtures['Date']=Date\n",
    "Fixtures['Time']=Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a7c6a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA WOMEN TOUR OF ENGLAND T20 SERIES 2022</td>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>County Ground,</td>\n",
       "      <td>15 SEP 2022</td>\n",
       "      <td>11:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022</td>\n",
       "      <td>1st ODI</td>\n",
       "      <td>County Ground,</td>\n",
       "      <td>18 SEP 2022</td>\n",
       "      <td>3:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>1st T20I</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium,</td>\n",
       "      <td>20 SEP 2022</td>\n",
       "      <td>7:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022</td>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>St Lawrence Ground,</td>\n",
       "      <td>21 SEP 2022</td>\n",
       "      <td>5:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>Vidarbha Cricket Association Stadium,</td>\n",
       "      <td>23 SEP 2022</td>\n",
       "      <td>7:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022</td>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>Lord's Cricket Ground,</td>\n",
       "      <td>24 SEP 2022</td>\n",
       "      <td>3:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>Rajiv Gandhi International Stadium,</td>\n",
       "      <td>25 SEP 2022</td>\n",
       "      <td>7:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022-23</td>\n",
       "      <td>1st T20I</td>\n",
       "      <td>Greenfield International Stadium,</td>\n",
       "      <td>28 SEP 2022</td>\n",
       "      <td>7:30 PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Title       Name  \\\n",
       "0    INDIA WOMEN TOUR OF ENGLAND T20 SERIES 2022  3rd T20I    \n",
       "1    INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022   1st ODI    \n",
       "2        AUSTRALIA TOUR OF INDIA T20 SERIES 2022  1st T20I    \n",
       "3    INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022   2nd ODI    \n",
       "4        AUSTRALIA TOUR OF INDIA T20 SERIES 2022  2nd T20I    \n",
       "5    INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022   3rd ODI    \n",
       "6        AUSTRALIA TOUR OF INDIA T20 SERIES 2022  3rd T20I    \n",
       "7  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022-23  1st T20I    \n",
       "\n",
       "                                           Place         Date       Time  \n",
       "0                                 County Ground,  15 SEP 2022  11:00 PM   \n",
       "1                                 County Ground,  18 SEP 2022   3:30 PM   \n",
       "2  Punjab Cricket Association IS Bindra Stadium,  20 SEP 2022   7:30 PM   \n",
       "3                            St Lawrence Ground,  21 SEP 2022   5:30 PM   \n",
       "4          Vidarbha Cricket Association Stadium,  23 SEP 2022   7:30 PM   \n",
       "5                         Lord's Cricket Ground,  24 SEP 2022   3:30 PM   \n",
       "6            Rajiv Gandhi International Stadium,  25 SEP 2022   7:30 PM   \n",
       "7              Greenfield International Stadium,  28 SEP 2022   7:30 PM   "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "895102cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f251e",
   "metadata": {},
   "source": [
    "## Answer-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b86a99b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# get webpage\n",
    "driver.get(\"https://www.guru99.com/\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8695776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click Selenium Button\n",
    "Selenium = driver.find_element(By.XPATH,'//div[@class = \"wp-block-kadence-column inner-column-2 kadence-column_f38d98-3a\"]') # click button\n",
    "try:\n",
    "    Selenium.click()\n",
    "except ElementNotInteractableException:#handling element not clickable exception\n",
    "    driver.get(Selenium.get_attribute('href'))\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e09dc630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click selenium exception handling  Button\n",
    "exception_handling = driver.find_element(By.XPATH,\"//a[@title='Selenium Exception Handling (Common Exceptions List)']\")\n",
    "try:\n",
    "    exception_handling.click()\n",
    "except ElementNotInteractableException:  #if the above code doesn't work/is not clickable then, the below code will handle it\n",
    "    driver.get(exception_handling.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "860d4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "desc=[]\n",
    "#Scrapping Name\n",
    "for i in driver.find_elements(By.XPATH,\"/html/body/div[1]/div/div/div/main/div/article/div/div/p[1]/strong\"):\n",
    "    name.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,\"/html/body/div[1]/div/div/div/main/div/article/div/div/p[1]\"):\n",
    "    desc.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "addd711b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exception name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. ElementNotVisibleException:</td>\n",
       "      <td>1. ElementNotVisibleException: This type of Se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Exception name  \\\n",
       "0  1. ElementNotVisibleException:   \n",
       "\n",
       "                                         Description  \n",
       "0  1. ElementNotVisibleException: This type of Se...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selenium_Exception=pd.DataFrame()\n",
    "Selenium_Exception['Exception name']=name\n",
    "Selenium_Exception['Description']=desc\n",
    "Selenium_Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "724b7a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3ec546",
   "metadata": {},
   "source": [
    "Not able to fetch all the exceptions .cant find the codes for it in inspect option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071cffcc",
   "metadata": {},
   "source": [
    "## Answer-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "206ad796",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "driver.get('https://www.statisticstimes.com')\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eaff954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'/html/body/div[1]/div/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15a99c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on Economy button\n",
    "driver.find_element(By.XPATH,\"//div[@class='navbar']/div[2]/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "274b936a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method WebElement.click of <selenium.webdriver.remote.webelement.WebElement (session=\"c21f48903544a5ee0dcdb944f69fb687\", element=\"3dbd6c52-b508-4d7b-92cb-91f13b024242\")>>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clicking on India\n",
    "driver.find_element(By.XPATH,\"//div[@class='dropdown-content']/a[3]\").click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f80f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on GDP of Indian Economy\n",
    "GDP = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f6d740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP2 = []\n",
    "Share = []\n",
    "GDPbillion = []\n",
    "# Scraping Rank\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "# Scraping State\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[2]\"):\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append(\"_\")\n",
    "    \n",
    "# Scraping GSDP at current price (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[4]\"):\n",
    "        GSDP2.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP2.append(\"_\")\n",
    "# Scraping Share (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[5]\"):\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append(\"_\")\n",
    "# Scraping GDP $ billion\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[6]\"):\n",
    "        GDPbillion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDPbillion.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b57cb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>STATE</th>\n",
       "      <th>GSDP2</th>\n",
       "      <th>SHARE</th>\n",
       "      <th>GDPbillion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>29</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>25,141</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>17,060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>24,534</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>22,488</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>20,947</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>17,797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK                      STATE      GSDP2   SHARE GDPbillion\n",
       "0     1                Maharashtra  2,632,792  13.94%    399.921\n",
       "1     2                 Tamil Nadu  1,630,208   8.63%    247.629\n",
       "2     3              Uttar Pradesh  1,584,764   8.39%    240.726\n",
       "3     4                    Gujarat  1,502,899   7.96%    228.290\n",
       "4     5                  Karnataka  1,493,127   7.91%    226.806\n",
       "..  ...                        ...        ...     ...        ...\n",
       "61   29                     Sikkim     25,141   0.15%     17,060\n",
       "62   30                   Nagaland     24,534   0.15%          -\n",
       "63   31          Arunachal Pradesh     22,488   0.13%          -\n",
       "64   32                    Mizoram     20,947   0.13%     17,797\n",
       "65   33  Andaman & Nicobar Islands          -       -          -\n",
       "\n",
       "[66 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDIA=pd.DataFrame()\n",
    "INDIA['RANK']=Rank\n",
    "INDIA['STATE']=State\n",
    "INDIA['GSDP2']=GSDP2\n",
    "INDIA['SHARE']=Share\n",
    "INDIA['GDPbillion']=GDPbillion\n",
    "INDIA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a84d46",
   "metadata": {},
   "source": [
    "GSDP 17-18 IS NOT AVAILABLE ON THE WEBSITE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a6fd74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96376371",
   "metadata": {},
   "source": [
    "## Answer-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "267e9314",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "url=('https://github.com/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06ed8b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on explore\n",
    "\n",
    "explore = driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[2]/div/nav/ul/li[3]')\n",
    "try:\n",
    "    explore.click()\n",
    "    time.sleep(5)\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(explore.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83e529c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on Trending\n",
    "\n",
    "trending = driver.find_element(By.XPATH,'//*[@href=\"/trending\"]')\n",
    "try:\n",
    "    driver.get(trending.get_attribute('href'))\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(trending.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d4b75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list:\n",
    "URLs = []\n",
    "repository_title = []\n",
    "Description = []\n",
    "Contributors = []\n",
    "Language = []\n",
    "lang = []\n",
    "\n",
    "#Fetching urls for each repository\n",
    "repository = driver.find_elements(By.XPATH,\"//h1[@class = 'h3 lh-condensed']//a\")\n",
    "for i in repository:\n",
    "    URLs.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e15e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Repository Title data\n",
    "title = driver.find_elements(By.XPATH,\"//h1[@class = 'h3 lh-condensed']\")\n",
    "for i in title:\n",
    "    repository_title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6aac88bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping data from all repository page\n",
    "for i in URLs:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "        # Scraping Repository Description data\n",
    "    try:\n",
    "        desc = driver.find_element(By.XPATH,\"//p[@class='f4 my-3']\")\n",
    "        Description.append(desc.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('-')\n",
    "        \n",
    "        \n",
    "    # Scraping Contributors Count data\n",
    "    try:\n",
    "        contributor = driver.find_element(By.XPATH,\"//*[contains(text(),'    Contributors ')]\")\n",
    "        Contributors.append(contributor.text.replace('Contributors',''))\n",
    "    except NoSuchElementException:\n",
    "        Contributors.append('-')\n",
    "        \n",
    "        \n",
    "     # Scraping Languages used data\n",
    "    lang=[]\n",
    "    try:\n",
    "        for i in driver.find_elements(By.XPATH,'//span[@class=\"color-fg-default text-bold mr-1\"]'):\n",
    "            lang.append(i.text)\n",
    "        Language.append(lang)\n",
    "    except NoSuchElementException:\n",
    "        lang.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb4139c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(repository_title),len(Description),len(Contributors),len(Language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b99785ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>danielgindi / Charts</td>\n",
       "      <td>Beautiful charts for iOS/tvOS/OSX! The Apple s...</td>\n",
       "      <td>150</td>\n",
       "      <td>[Swift, Objective-C, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>surrealdb / surrealdb</td>\n",
       "      <td>A scalable, distributed, collaborative, docume...</td>\n",
       "      <td>11</td>\n",
       "      <td>[Rust, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheAlgorithms / Python</td>\n",
       "      <td>All Algorithms implemented in Python</td>\n",
       "      <td>831</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SerenityOS / ladybird</td>\n",
       "      <td>Ladybird web browser</td>\n",
       "      <td>16</td>\n",
       "      <td>[C++, CMake, Java]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>divamgupta / diffusionbee-stable-diffusion-ui</td>\n",
       "      <td>Diffusion Bee is the easiest way to run Stable...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Jupyter Notebook, Python, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>karpathy / nn-zero-to-hero</td>\n",
       "      <td>Neural Networks: Zero to Hero</td>\n",
       "      <td>-</td>\n",
       "      <td>[Jupyter Notebook]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EbookFoundation / free-programming-books</td>\n",
       "      <td>📚 Freely available programming books</td>\n",
       "      <td>2,002</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>twitter / compose-rules</td>\n",
       "      <td>Static checks to aid with a healthy adoption o...</td>\n",
       "      <td>8</td>\n",
       "      <td>[Kotlin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n8n-io / n8n</td>\n",
       "      <td>Free and source-available fair-code licensed w...</td>\n",
       "      <td>302</td>\n",
       "      <td>[TypeScript, Vue, SCSS, JavaScript, HTML, Dock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InterviewReady / system-design-resources</td>\n",
       "      <td>These are the best resources for System Design...</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>moby / moby</td>\n",
       "      <td>Moby Project - a collaborative project for the...</td>\n",
       "      <td>2,178</td>\n",
       "      <td>[Go, Shell, Dockerfile, PowerShell, Makefile, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Alamofire / Alamofire</td>\n",
       "      <td>Elegant HTTP Networking in Swift</td>\n",
       "      <td>240</td>\n",
       "      <td>[Swift]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AykutSarac / jsoncrack.com</td>\n",
       "      <td>🔮 Seamlessly visualize your JSON data instantl...</td>\n",
       "      <td>14</td>\n",
       "      <td>[TypeScript, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pocketbase / pocketbase</td>\n",
       "      <td>Open Source realtime backend in 1 file</td>\n",
       "      <td>15</td>\n",
       "      <td>[Go, Svelte, SCSS, JavaScript, HTML, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ascoders / weekly</td>\n",
       "      <td>前端精读周刊。帮你理解最前沿、实用的技术。</td>\n",
       "      <td>67</td>\n",
       "      <td>[JavaScript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jellyfin / jellyfin</td>\n",
       "      <td>The Free Software Media System</td>\n",
       "      <td>761</td>\n",
       "      <td>[C#, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>apptension / developer-handbook</td>\n",
       "      <td>An opinionated guide on how to become a profes...</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vasanthk / how-web-works</td>\n",
       "      <td>What happens behind the scenes when we type ww...</td>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rust-lang / rust</td>\n",
       "      <td>Empowering everyone to build reliable and effi...</td>\n",
       "      <td>4,017</td>\n",
       "      <td>[Rust, JavaScript, HTML, Python, Makefile, She...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dotnet / core</td>\n",
       "      <td>Home repository for .NET Core</td>\n",
       "      <td>302</td>\n",
       "      <td>[PowerShell, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>microsoft / playwright</td>\n",
       "      <td>Playwright is a framework for Web Testing and ...</td>\n",
       "      <td>294</td>\n",
       "      <td>[TypeScript, HTML, C++, CSS, JavaScript, Objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gothinkster / realworld</td>\n",
       "      <td>\"The mother of all demo apps\" — Exemplary full...</td>\n",
       "      <td>73</td>\n",
       "      <td>[Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SerenityOS / serenity</td>\n",
       "      <td>The Serenity Operating System 🐞</td>\n",
       "      <td>751</td>\n",
       "      <td>[C++, JavaScript, HTML, C, Shell, CMake, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>jwasham / coding-interview-university</td>\n",
       "      <td>A complete computer science study plan to beco...</td>\n",
       "      <td>273</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>joeyballentine / chaiNNer</td>\n",
       "      <td>A flowchart/node-based image processing GUI ai...</td>\n",
       "      <td>10</td>\n",
       "      <td>[TypeScript, Python, JavaScript, Other]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Repository title  \\\n",
       "0                            danielgindi / Charts   \n",
       "1                           surrealdb / surrealdb   \n",
       "2                          TheAlgorithms / Python   \n",
       "3                           SerenityOS / ladybird   \n",
       "4   divamgupta / diffusionbee-stable-diffusion-ui   \n",
       "5                      karpathy / nn-zero-to-hero   \n",
       "6        EbookFoundation / free-programming-books   \n",
       "7                         twitter / compose-rules   \n",
       "8                                    n8n-io / n8n   \n",
       "9        InterviewReady / system-design-resources   \n",
       "10                                    moby / moby   \n",
       "11                          Alamofire / Alamofire   \n",
       "12                     AykutSarac / jsoncrack.com   \n",
       "13                        pocketbase / pocketbase   \n",
       "14                              ascoders / weekly   \n",
       "15                            jellyfin / jellyfin   \n",
       "16                apptension / developer-handbook   \n",
       "17                       vasanthk / how-web-works   \n",
       "18                               rust-lang / rust   \n",
       "19                                  dotnet / core   \n",
       "20                         microsoft / playwright   \n",
       "21                        gothinkster / realworld   \n",
       "22                          SerenityOS / serenity   \n",
       "23          jwasham / coding-interview-university   \n",
       "24                      joeyballentine / chaiNNer   \n",
       "\n",
       "                               Repository description Contributors count  \\\n",
       "0   Beautiful charts for iOS/tvOS/OSX! The Apple s...                150   \n",
       "1   A scalable, distributed, collaborative, docume...                 11   \n",
       "2                All Algorithms implemented in Python                831   \n",
       "3                                Ladybird web browser                 16   \n",
       "4   Diffusion Bee is the easiest way to run Stable...                  -   \n",
       "5                       Neural Networks: Zero to Hero                  -   \n",
       "6                📚 Freely available programming books              2,002   \n",
       "7   Static checks to aid with a healthy adoption o...                  8   \n",
       "8   Free and source-available fair-code licensed w...                302   \n",
       "9   These are the best resources for System Design...                  5   \n",
       "10  Moby Project - a collaborative project for the...              2,178   \n",
       "11                   Elegant HTTP Networking in Swift                240   \n",
       "12  🔮 Seamlessly visualize your JSON data instantl...                 14   \n",
       "13             Open Source realtime backend in 1 file                 15   \n",
       "14                              前端精读周刊。帮你理解最前沿、实用的技术。                 67   \n",
       "15                     The Free Software Media System                761   \n",
       "16  An opinionated guide on how to become a profes...                  4   \n",
       "17  What happens behind the scenes when we type ww...                  8   \n",
       "18  Empowering everyone to build reliable and effi...              4,017   \n",
       "19                      Home repository for .NET Core                302   \n",
       "20  Playwright is a framework for Web Testing and ...                294   \n",
       "21  \"The mother of all demo apps\" — Exemplary full...                 73   \n",
       "22                    The Serenity Operating System 🐞                751   \n",
       "23  A complete computer science study plan to beco...                273   \n",
       "24  A flowchart/node-based image processing GUI ai...                 10   \n",
       "\n",
       "                                        Language used  \n",
       "0                         [Swift, Objective-C, Other]  \n",
       "1                                       [Rust, Other]  \n",
       "2                                            [Python]  \n",
       "3                                  [C++, CMake, Java]  \n",
       "4                   [Jupyter Notebook, Python, Other]  \n",
       "5                                  [Jupyter Notebook]  \n",
       "6                                                  []  \n",
       "7                                            [Kotlin]  \n",
       "8   [TypeScript, Vue, SCSS, JavaScript, HTML, Dock...  \n",
       "9                                                  []  \n",
       "10  [Go, Shell, Dockerfile, PowerShell, Makefile, ...  \n",
       "11                                            [Swift]  \n",
       "12                                [TypeScript, Other]  \n",
       "13        [Go, Svelte, SCSS, JavaScript, HTML, Shell]  \n",
       "14                                       [JavaScript]  \n",
       "15                                        [C#, Other]  \n",
       "16                                                 []  \n",
       "17                                                 []  \n",
       "18  [Rust, JavaScript, HTML, Python, Makefile, She...  \n",
       "19                                [PowerShell, Shell]  \n",
       "20  [TypeScript, HTML, C++, CSS, JavaScript, Objec...  \n",
       "21                                            [Shell]  \n",
       "22    [C++, JavaScript, HTML, C, Shell, CMake, Other]  \n",
       "23                                                 []  \n",
       "24            [TypeScript, Python, JavaScript, Other]  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Frame\n",
    "\n",
    "Github=pd.DataFrame({})\n",
    "Github['Repository title'] = repository_title\n",
    "Github['Repository description'] = Description\n",
    "Github['Contributors count'] = Contributors\n",
    "Github['Language used'] = Language\n",
    "Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38a8ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914683e5",
   "metadata": {},
   "source": [
    "## Answer-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26f583c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "# Getting the webpage of mentioned url \n",
    "driver.get('https://www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9166175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on charts\n",
    "charts=driver.find_element(By.XPATH,'//*[@id=\"main-wrapper\"]/header/div[2]/div/nav/ul/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8bcf8443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists\n",
    "Song_Name = []\n",
    "Artist_Name = []\n",
    "Last_week_rank = []\n",
    "Peak_rank = []\n",
    "Weeks_on_board = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f16d666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping name\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]'):\n",
    "    Song_Name.append(i.text)\n",
    "len(Song_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4001c70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrappin Artist name 1 st one\n",
    "Artist_Name.append(driver.find_element(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet']\").text)\n",
    "#Remainig Artist Name\n",
    "artistTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "Artist_Name.extend([i.text for i in artistTag])\n",
    "#Scapping Rank\n",
    "rank=[]\n",
    "rankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet']\")\n",
    "rank.extend([i.text for i in rankTag[:3]])\n",
    "#Remaining RAnk\n",
    "Rank=[]\n",
    "RankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max']\")\n",
    "Rank.extend([i.text for i in RankTag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d61abaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing ''\n",
    "for i in Rank:\n",
    "    if i=='':\n",
    "        Rank.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2742536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing as per requirement\n",
    "lastweekpos=Rank[0::3]\n",
    "lastweekpos.insert(0,rank[0])\n",
    "peakPos=Rank[1::3]\n",
    "peakPos.insert(0,rank[1])\n",
    "weeksonBoard=Rank[2::3]\n",
    "weeksonBoard.insert(0,rank[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7b2bb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 133, 133, 133)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check length of all\n",
    "len(Song_Name),len(Artist_Name),len(lastweekpos),len(peakPos),len(weeksonBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f9c095d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SongName</th>\n",
       "      <th>ArtistName</th>\n",
       "      <th>Last Week</th>\n",
       "      <th>PeekPosition</th>\n",
       "      <th>Weeks On board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As It Was\\nHarry Styles\\n1\\n1\\n23</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad Habit\\nSteve Lacy\\n2\\n2\\n10</td>\n",
       "      <td>Steve Lacy</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Late Night Talking\\nHarry Styles\\n12\\n3\\n16</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunroof\\nNicky Youre &amp; dazy\\n5\\n4\\n15</td>\n",
       "      <td>Nicky Youre &amp; dazy</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>About Damn Time\\nLizzo\\n3\\n1\\n21</td>\n",
       "      <td>Lizzo</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Thought You Should Know\\nMorgan Wallen\\n96\\n12...</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>88</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Country On\\nLuke Bryan\\n-\\n76\\n3</td>\n",
       "      <td>Luke Bryan</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Static\\nSteve Lacy\\n-\\n98\\n1</td>\n",
       "      <td>Steve Lacy</td>\n",
       "      <td>83</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Billie Eilish.\\nArmani White\\n-\\n99\\n1</td>\n",
       "      <td>Armani White</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Sin Fin\\nRomeo Santos &amp; Justin Timberlake\\n-\\n...</td>\n",
       "      <td>Romeo Santos &amp; Justin Timberlake</td>\n",
       "      <td>93</td>\n",
       "      <td>84</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             SongName  \\\n",
       "0                   As It Was\\nHarry Styles\\n1\\n1\\n23   \n",
       "1                     Bad Habit\\nSteve Lacy\\n2\\n2\\n10   \n",
       "2         Late Night Talking\\nHarry Styles\\n12\\n3\\n16   \n",
       "3               Sunroof\\nNicky Youre & dazy\\n5\\n4\\n15   \n",
       "4                    About Damn Time\\nLizzo\\n3\\n1\\n21   \n",
       "..                                                ...   \n",
       "95  Thought You Should Know\\nMorgan Wallen\\n96\\n12...   \n",
       "96                   Country On\\nLuke Bryan\\n-\\n76\\n3   \n",
       "97                       Static\\nSteve Lacy\\n-\\n98\\n1   \n",
       "98             Billie Eilish.\\nArmani White\\n-\\n99\\n1   \n",
       "99  Sin Fin\\nRomeo Santos & Justin Timberlake\\n-\\n...   \n",
       "\n",
       "                          ArtistName Last Week PeekPosition Weeks On board  \n",
       "0                       Harry Styles         1            1             23  \n",
       "1                         Steve Lacy         2            2             10  \n",
       "2                       Harry Styles        12            3             16  \n",
       "3                 Nicky Youre & dazy         5            4             15  \n",
       "4                              Lizzo         3            1             21  \n",
       "..                               ...       ...          ...            ...  \n",
       "95                     Morgan Wallen        88           42              5  \n",
       "96                        Luke Bryan                                        \n",
       "97                        Steve Lacy        83           18             18  \n",
       "98                      Armani White                                        \n",
       "99  Romeo Santos & Justin Timberlake        93           84              4  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "df=pd.DataFrame()\n",
    "df['SongName']=Song_Name[0:100]\n",
    "df['ArtistName']=Artist_Name\n",
    "df['Last Week']=lastweekpos[0:100]\n",
    "df[\"PeekPosition\"]=peakPos[0:100]\n",
    "df['Weeks On board']=weeksonBoard[0:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3afe16d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf2b97f",
   "metadata": {},
   "source": [
    "## Answer-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c053f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "driver.maximize_window()\n",
    "# Getting the webpage of mentioned url \n",
    "url=('https://www.naukri.com/')\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a9607af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching urls to navigate recruiter page\n",
    "recruiter = driver.find_element(By.XPATH,'//a[@title=\"Search Jobs\"]')\n",
    "page_url = recruiter.get_attribute(\"href\")\n",
    "\n",
    "driver.get(page_url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cadb5347",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//div[@class='inpWrap']//input\"}\n  (Session info: chrome=105.0.5195.102)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x006178B3+2193587]\n\tOrdinal0 [0x005B0681+1771137]\n\tOrdinal0 [0x004C41A8+803240]\n\tOrdinal0 [0x004F24A0+992416]\n\tOrdinal0 [0x004F273B+993083]\n\tOrdinal0 [0x0051F7C2+1177538]\n\tOrdinal0 [0x0050D7F4+1103860]\n\tOrdinal0 [0x0051DAE2+1170146]\n\tOrdinal0 [0x0050D5C6+1103302]\n\tOrdinal0 [0x004E77E0+948192]\n\tOrdinal0 [0x004E86E6+952038]\n\tGetHandleVerifier [0x008C0CB2+2738370]\n\tGetHandleVerifier [0x008B21B8+2678216]\n\tGetHandleVerifier [0x006A17AA+512954]\n\tGetHandleVerifier [0x006A0856+509030]\n\tOrdinal0 [0x005B743B+1799227]\n\tOrdinal0 [0x005BBB68+1817448]\n\tOrdinal0 [0x005BBC55+1817685]\n\tOrdinal0 [0x005C5230+1856048]\n\tBaseThreadInitThunk [0x7707FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x771C7B5E+286]\n\tRtlGetAppContainerNamedObjectPath [0x771C7B2E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5372/623302463.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fetching search button, sending keys and clicking on it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msearch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"//div[@class='inpWrap']//input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data science \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbtn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/button'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    854\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    857\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    436\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//div[@class='inpWrap']//input\"}\n  (Session info: chrome=105.0.5195.102)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x006178B3+2193587]\n\tOrdinal0 [0x005B0681+1771137]\n\tOrdinal0 [0x004C41A8+803240]\n\tOrdinal0 [0x004F24A0+992416]\n\tOrdinal0 [0x004F273B+993083]\n\tOrdinal0 [0x0051F7C2+1177538]\n\tOrdinal0 [0x0050D7F4+1103860]\n\tOrdinal0 [0x0051DAE2+1170146]\n\tOrdinal0 [0x0050D5C6+1103302]\n\tOrdinal0 [0x004E77E0+948192]\n\tOrdinal0 [0x004E86E6+952038]\n\tGetHandleVerifier [0x008C0CB2+2738370]\n\tGetHandleVerifier [0x008B21B8+2678216]\n\tGetHandleVerifier [0x006A17AA+512954]\n\tGetHandleVerifier [0x006A0856+509030]\n\tOrdinal0 [0x005B743B+1799227]\n\tOrdinal0 [0x005BBB68+1817448]\n\tOrdinal0 [0x005BBC55+1817685]\n\tOrdinal0 [0x005C5230+1856048]\n\tBaseThreadInitThunk [0x7707FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x771C7B5E+286]\n\tRtlGetAppContainerNamedObjectPath [0x771C7B2E+238]\n"
     ]
    }
   ],
   "source": [
    "# Fetching search button, sending keys and clicking on it\n",
    "search = driver.find_element(By.XPATH,\"//div[@class='inpWrap']//input\") \n",
    "search.send_keys(\"Data science \")           \n",
    "btn = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/button').click()     \n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1299ac",
   "metadata": {},
   "source": [
    "Not able to find any code on website further"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ddf1a5",
   "metadata": {},
   "source": [
    "## Answer-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9bece9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to webdriver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# get webpage\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b67423bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Bookname = []\n",
    "Authorname = []\n",
    "Volumessold = []\n",
    "Publisher = []\n",
    "Genre = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57d8b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping book names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody//tr/td[2]\"):\n",
    "    Bookname.append(i.text)\n",
    "    \n",
    "#Scraping author names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[3]\"):\n",
    "    try:\n",
    "        if i.text == '0' : raise NoSuchElementException\n",
    "        Authorname.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Authorname.append('-')\n",
    "time.sleep(1)\n",
    "\n",
    "#Scraping data of volumes sold\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[4]\"):\n",
    "    Volumessold.append(i.text)\n",
    "    \n",
    "#Scraping data of publisher names\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[5]\"):\n",
    "    Publisher.append(i.text)\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[6]\"):\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc98d3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating dataframe for scraped data\n",
    "Novels=pd.DataFrame({})\n",
    "Novels['Book Name'] = Bookname\n",
    "Novels['Author'] = Authorname\n",
    "Novels['Volume sold'] = Volumessold\n",
    "Novels['Publisher'] = Publisher\n",
    "Novels['Genre'] = Genre\n",
    "Novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f823109",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e3d677",
   "metadata": {},
   "source": [
    "## Answer-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9d00446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to webdriver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "# get webpage\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "98f86c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists.\n",
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []\n",
    "\n",
    "#Scraping data of Names\n",
    "for i in driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\"):\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scraping data of Year span\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    Year_span.append(i.text)\n",
    "    \n",
    "#Scraping data of Run time\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='runtime']\"):\n",
    "    Run_time.append(i.text)\n",
    "    \n",
    "#Scraping data of Ratings\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']//span[2]\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='genre']\"):\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "#Scraping data of votes\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='lister-item-content']//p[4]/span[2]\"):\n",
    "    Votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8b0fb2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,049,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,145,233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>968,258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>288,820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>248,395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>49,556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>60,561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>194,776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>236,428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,049,300  \n",
       "1    51 min     8.7  1,145,233  \n",
       "2    44 min     8.1    968,258  \n",
       "3    60 min     7.5    288,820  \n",
       "4    43 min     7.6    248,395  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     49,556  \n",
       "96   50 min     7.8     60,561  \n",
       "97   42 min     8.1    194,776  \n",
       "98   45 min     7.1     41,021  \n",
       "99  572 min     8.6    236,428  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe for scraped data\n",
    "TVseries=pd.DataFrame({})\n",
    "TVseries['Name'] = Name\n",
    "TVseries['Year Span'] = Year_span\n",
    "TVseries['Genre'] = Genre\n",
    "TVseries['Run Time'] = Run_time\n",
    "TVseries['Ratings'] = Ratings\n",
    "TVseries['Votes'] = Votes\n",
    "TVseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d8f2a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00df65",
   "metadata": {},
   "source": [
    "## Answer-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf22f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to webdriver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "# get webpage\n",
    "driver.get(\" https://archive.ics.uci.edu/\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a382fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding view all dataset button from the webpage\n",
    "viewall_dataset = driver.find_element(By.XPATH,\"//tbody[1]//tr/td[2]/span[2]/a\")    \n",
    "page_url = viewall_dataset.get_attribute(\"href\")\n",
    "driver.get(page_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2dffffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching page urls of all datasets \n",
    "view_list = driver.find_element(By.XPATH,\"/html/body/table[2]/tbody/tr/td[2]/table[1]/tbody/tr/td[2]/p/a\")  \n",
    "list_url = view_list.get_attribute(\"href\")           \n",
    "driver.get(list_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1b4f17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching urls for each dataset\n",
    "dataset_url = driver.find_elements(By.XPATH,\"//p[@class='normal']//b/a\")    \n",
    "\n",
    "urls = []     \n",
    "for i in dataset_url:\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8c0f3394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "Dataset_name = []\n",
    "Data_type = []\n",
    "Task = []\n",
    "Attribute_type = []\n",
    "No_of_instances = []\n",
    "No_of_attributes = []\n",
    "Year = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bc531ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #Scraping Dataset name\n",
    "    try: \n",
    "        dataset_name = driver.find_element(By.XPATH,\"//span[@class='heading']\")\n",
    "        Dataset_name.append(dataset_name.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset_name.append('-')\n",
    "    \n",
    "    \n",
    "    #Scraping data type\n",
    "    try:\n",
    "        data_type = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr/td[2]\")\n",
    "        if data_type.text == \"N/A\": raise NoSuchElementException\n",
    "        Data_type.append(data_type.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append('-')\n",
    "    \n",
    "    #scraping Task\n",
    "    try:\n",
    "        task = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[3]/td[2]\")\n",
    "        if task.text == \"N/A\": raise NoSuchElementException\n",
    "        Task.append(task.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('-')\n",
    "    \n",
    "    \n",
    "    # Scraping Attribute type\n",
    "    try:\n",
    "        attribute_type = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[2]/td[2]\")\n",
    "        if attribute_type.text == \"N/A\": raise NoSuchElementException\n",
    "        Attribute_type.append(attribute_type.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute_type.append('-')\n",
    "    \n",
    "    \n",
    "    # Scraping No of instances\n",
    "    try:\n",
    "        instances = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr/td[4]\")\n",
    "        if instances.text == \"N/A\": raise NoSuchElementException\n",
    "        No_of_instances.append(instances.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_instances.append('-')\n",
    "    \n",
    "    \n",
    "    # Scraping No of attributes\n",
    "    try:\n",
    "        attribute = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[2]/td[4]\")\n",
    "        if attribute.text == \"N/A\": raise NoSuchElementException\n",
    "        No_of_attributes.append(attribute.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_attributes.append('-')\n",
    "        \n",
    "      \n",
    "    # Scraping year\n",
    "    try:\n",
    "        year = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[2]/td[6]\")\n",
    "        if year.text == \"N/A\": raise NoSuchElementException\n",
    "        Year.append(year.text[:4])\n",
    "    except NoSuchElementException:\n",
    "        Year.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8ae713ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instance</th>\n",
       "      <th>No of attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4 GHZ Indoor Channel Measurements Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>7840</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Road Network (North Jutland, Denmark) Data Set</td>\n",
       "      <td>Sequential, Text</td>\n",
       "      <td>Regression, Clustering</td>\n",
       "      <td>Real</td>\n",
       "      <td>434874</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3W dataset Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>1984</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9mers from cullpdb Data Set</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>158716</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>: Simulated Data set of Iraqi tourism places D...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>-</td>\n",
       "      <td>232</td>\n",
       "      <td>16</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Youtube cookery channels viewers comments in H...</td>\n",
       "      <td>Multivariate, Text</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>9800</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>YouTube Multiview Video Games Dataset Data Set</td>\n",
       "      <td>Multivariate, Text</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>120000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>YouTube Spam Collection Data Set</td>\n",
       "      <td>Text</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>1956</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Z-Alizadeh Sani Data Set</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>56</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Zoo Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>101</td>\n",
       "      <td>17</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Data Name  \\\n",
       "0         2.4 GHZ Indoor Channel Measurements Data Set   \n",
       "1    3D Road Network (North Jutland, Denmark) Data Set   \n",
       "2                                  3W dataset Data Set   \n",
       "3                          9mers from cullpdb Data Set   \n",
       "4    : Simulated Data set of Iraqi tourism places D...   \n",
       "..                                                 ...   \n",
       "617  Youtube cookery channels viewers comments in H...   \n",
       "618     YouTube Multiview Video Games Dataset Data Set   \n",
       "619                   YouTube Spam Collection Data Set   \n",
       "620                           Z-Alizadeh Sani Data Set   \n",
       "621                                       Zoo Data Set   \n",
       "\n",
       "                     Data Type                        Task  \\\n",
       "0                 Multivariate              Classification   \n",
       "1             Sequential, Text      Regression, Clustering   \n",
       "2    Multivariate, Time-Series  Classification, Clustering   \n",
       "3                   Sequential  Classification, Regression   \n",
       "4                 Multivariate  Classification, Clustering   \n",
       "..                         ...                         ...   \n",
       "617         Multivariate, Text              Classification   \n",
       "618         Multivariate, Text  Classification, Clustering   \n",
       "619                       Text              Classification   \n",
       "620                          -              Classification   \n",
       "621               Multivariate              Classification   \n",
       "\n",
       "           Attribute type No of instance No of attributes  Year  \n",
       "0                    Real           7840                5  2018  \n",
       "1                    Real         434874                4  2013  \n",
       "2           Integer, Real           1984                8  2019  \n",
       "3                    Real         158716                4  2021  \n",
       "4                       -            232               16  2020  \n",
       "..                    ...            ...              ...   ...  \n",
       "617                     -           9800                3  2019  \n",
       "618         Integer, Real         120000          1000000  2013  \n",
       "619                     -           1956                5  2017  \n",
       "620         Integer, Real            303               56  2017  \n",
       "621  Categorical, Integer            101               17  1990  \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe \n",
    "\n",
    "ML=pd.DataFrame({})\n",
    "ML['Data Name'] = Dataset_name[:622]\n",
    "ML['Data Type'] = Data_type[:622]\n",
    "ML['Task'] = Task[:622]\n",
    "ML['Attribute type'] = Attribute_type[:622]\n",
    "ML['No of instance'] = No_of_instances[:622]\n",
    "ML['No of attributes'] = No_of_attributes[:622]\n",
    "ML['Year'] = Year[:622]\n",
    "ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "99ef93ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d217c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
